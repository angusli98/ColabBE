{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angusli98/ColabBE/blob/main/ColabBE_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ColabBE: automated base editing analysis for ClinVar variants\n",
        "\n",
        "Written by Angus Li with contributions from Alvin Hsu\n",
        "\n",
        "Editing predictions based on BE-Hive by Max W. Shen (https://www.crisprbehive.design/), an implementation of machine learning models for base editing outcomes described in:\n",
        "\n",
        "**Arbab M**, **Shen MW**, Mok B, et al. Determinants of Base Editing Outcomes from Target Library Analysis and Machine Learning. *Cell*. 2020;182(2):463-480.e30. doi:10.1016/j.cell.2020.05.037\n",
        "\n",
        "Cas9 variant recommendations based on HT-PAMDA data courtesy of Rachel A. Silverstein and Benjamin P. Kleinstiver, as described in:\n",
        "\n",
        "**Silverstein RA**, Kim N, Kroell AS, et al. Custom CRISPR-Cas9 PAM variants via scalable engineering and machine learning. *Nature*. Published online April 22, 2025. doi:10.1038/s41586-025-09021-y\n",
        "\n",
        "For coding mutations, ColabBE analyzes base editing strategies that are expected to correct the mutated codon to any codon for the reference amino acid. For non-coding mutations, ColabBE analyzes base editing strategies that are expected to revert the mutated base to the reference sequence.\n",
        "\n",
        "Source code is available under the [GNU Affero General Public License, version 3](https://www.gnu.org/licenses/agpl-3.0.en.html) from this notebook or at https://github.com/angusli98/ColabBE.\n",
        "\n",
        "**Instructions**:\n",
        "\n",
        "- To run, make a copy of this notebook in your own Google Drive (File > Save a copy in Drive). Use this copy for analysis.\n",
        "- First run the section titled \"Mount Google Drive, install/import libraries and define functions\" by clicking the \"Play\" button to the left.\n",
        "- The optional \"Search ClinVar for ClinVar IDs\" section can be used to find ClinVar IDs of interest using more general search terms.\n",
        "- Specify all parameters under \"Perform analysis and download results,\" then start analysis by clicking the \"Play\" button to the left. A CPU runtime is sufficient.\n",
        "- After analysis is finished, it is recommended to disconnect and delete the runtime (menu in the top right corner) to avoid wasting resources.\n",
        "\n",
        "**Results interpretation**:\n",
        "\n",
        "- When analysis is finished, a zip archive is provided for download, containing all output files. There is a known issue decompressing some files with Windows Explorer; archives can be fully unpacked using [7-Zip](https://www.7-zip.org/) in such cases.\n",
        "- For each ClinVar ID with potential corrective strategies, two files are provided: `...predicted base editing statistics.xlsx` and `...predicted sequence distributions.xlsx`.\n",
        "-  `...predicted base editing statistics.xlsx` contains the editor, 20-nucleotide spacer, and 4-nucleotide PAM for each analyzed base editing strategy, as well as the fraction of predicted perfect correction, Z-score, percentile, and predicted target efficiency given the specified `average_editing_efficiency`. For coding mutations, perfect correction is defined as the fraction of **edited** sequencing reads for which the corresponding translated protein sequence is reverted to the same as the reference sequence. For non-coding mutations, perfect correction is defined as the fraction of **edited** sequencing reads for which the DNA sequence exactly matches the reference sequence. Cas9 variant recommendations and corresponding HT-PAMDA scores are also provided based on the PAM sequence.\n",
        "- `...predicted sequence distributions.xlsx` contains the predicted fraction of sequences resulting from each analyzed editing strategy. Each editor, spacer, and PAM combination is a separate sheet in the file.\n",
        "- A file named `Summary of editor candidates above threshold.xlsx` is also provided. This is a listing of all editor candidates, with their corresponding ClinVar IDs and variant names, with predicted perfect correction above the cutoff specified in `threshold`.\n",
        "- A file named `Variants with editor candidates above threshold.xlsx` is provided. This lists all analyzed variants with at least one editor candidate with predicted perfect correction above the cutoff specified in `threshold`.\n",
        "- All output files are also stored in a timestamped folder on your Google Drive. This can be deleted after analysis is finished if space is limited."
      ],
      "metadata": {
        "id": "JZNTi8ZL8XqC"
      },
      "id": "JZNTi8ZL8XqC"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69eed071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69eed071",
        "outputId": "4be07d6d-6206-41b8-a72c-0482e122453c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n",
            "Mounted at /content/gdrive\n",
            "--2025-09-10 21:07:16--  https://github.com/angusli98/ColabBE/raw/refs/heads/main/PAM_scores.xlsx\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/angusli98/ColabBE/refs/heads/main/PAM_scores.xlsx [following]\n",
            "--2025-09-10 21:07:17--  https://raw.githubusercontent.com/angusli98/ColabBE/refs/heads/main/PAM_scores.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17300 (17K) [application/octet-stream]\n",
            "Saving to: ‘PAM_scores.xlsx’\n",
            "\n",
            "PAM_scores.xlsx     100%[===================>]  16.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-10 21:07:17 (37.2 MB/s) - ‘PAM_scores.xlsx’ saved [17300/17300]\n",
            "\n",
            "Cloning into 'be_predict_bystander'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Total 142 (delta 0), reused 0 (delta 0), pack-reused 142 (from 1)\u001b[K\n",
            "Receiving objects: 100% (142/142), 16.53 MiB | 31.34 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "Cloning into 'be_predict_efficiency'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Total 106 (delta 0), reused 0 (delta 0), pack-reused 106 (from 1)\u001b[K\n",
            "Receiving objects: 100% (106/106), 11.17 MiB | 24.45 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ],
      "source": [
        "# @title (Required) Mount Google Drive, install/import libraries and define functions { display-mode: \"form\" }\n",
        "!pip install biopython\n",
        "import requests\n",
        "from Bio import Seq\n",
        "from Bio import Entrez\n",
        "import io\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import shutil\n",
        "import re\n",
        "drive.mount('/content/gdrive')\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "!wget https://github.com/angusli98/ColabBE/raw/refs/heads/main/PAM_scores.xlsx\n",
        "pam_dict = pd.read_excel('PAM_scores.xlsx', index_col = 'PAM').to_dict(orient='index')\n",
        "from contextlib import contextmanager\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn._loss import HalfSquaredError\n",
        "from sklearn.tree._tree import Tree as SKTree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import contextlib\n",
        "!git clone https://github.com/maxwshen/be_predict_bystander.git\n",
        "!git clone https://github.com/maxwshen/be_predict_efficiency.git\n",
        "import sys\n",
        "sys.path.append('/content/be_predict_bystander')\n",
        "sys.path.append('/content/be_predict_efficiency')\n",
        "from be_predict_efficiency import predict as be_efficiency_model\n",
        "from be_predict_bystander import predict as bystander_model\n",
        "from scipy.special import logit,expit\n",
        "from scipy.stats import norm\n",
        "\n",
        "class _PatchedTree(SKTree):\n",
        "    def __setstate__(self, state):\n",
        "        nodes = state.get(\"nodes\")\n",
        "        if nodes is not None and nodes.dtype.names and 'missing_go_to_left' not in nodes.dtype.names:\n",
        "            expected_dtype = np.dtype([\n",
        "                ('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'),\n",
        "                ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'),\n",
        "                ('weighted_n_node_samples', '<f8'), ('missing_go_to_left', 'u1'),\n",
        "            ])\n",
        "            fixed_nodes = np.zeros(nodes.shape[0], dtype=expected_dtype)\n",
        "            for field in nodes.dtype.names:\n",
        "                fixed_nodes[field] = nodes[field]\n",
        "            fixed_nodes['missing_go_to_left'] = True\n",
        "            state['nodes'] = fixed_nodes\n",
        "        super().__setstate__(state)\n",
        "\n",
        "\n",
        "class _FixUnpickler(pkl.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'sklearn.ensemble.gradient_boosting':\n",
        "            module = 'sklearn.ensemble'\n",
        "        elif module == 'sklearn.tree.tree':\n",
        "            module = 'sklearn.tree'\n",
        "        if module == 'sklearn.ensemble' and name == 'LeastSquaresError':\n",
        "            return HalfSquaredError\n",
        "        elif module == 'sklearn.ensemble' and name == 'MeanEstimator':\n",
        "            return DummyRegressor\n",
        "        elif module == 'sklearn.tree._tree' and name == 'Tree':\n",
        "            return _PatchedTree\n",
        "        return super().find_class(module, name)\n",
        "\n",
        "    def load(self):\n",
        "        obj = super().load()\n",
        "        if isinstance(obj, GradientBoostingRegressor):\n",
        "            estimators = getattr(obj, 'estimators_', None)\n",
        "            if estimators is not None:\n",
        "                for tree in estimators.ravel():\n",
        "                    if not hasattr(tree, 'monotonic_cst'):\n",
        "                        tree.monotonic_cst = np.array([], dtype=np.int8)\n",
        "            if not hasattr(obj, '_loss'):\n",
        "                obj._loss = HalfSquaredError()\n",
        "            if hasattr(obj, 'init_') and isinstance(obj.init_, DummyRegressor) and \\\n",
        "                    not hasattr(obj.init_, 'strategy') and hasattr(obj.init_, 'mean'):\n",
        "                mean = obj.init_.mean\n",
        "                obj.init_.strategy = 'constant'\n",
        "                obj.init_.constant_ = np.array([[mean]])\n",
        "                obj.init_.n_outputs_ = 1\n",
        "        return obj\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def patch_pickle():\n",
        "    import pickle\n",
        "    _orig = pickle.load\n",
        "    pickle.load = lambda f: _FixUnpickler(f).load()\n",
        "    yield\n",
        "    pickle.load = _orig\n",
        "\n",
        "def cvIDtoHg38Coords(cvID, email):\n",
        "    ASM_MAP = {\"NCBI36\": \"hg18\", \"GRCh37\": \"hg19\", \"GRCh38\": \"hg38\", \"T2T-CHM13v2.0\": \"hs1\"}\n",
        "    Entrez.email = email\n",
        "    records = Entrez.read(Entrez.esummary(db='clinvar', id=cvId), validate = False)\n",
        "    try:\n",
        "      varData = records['DocumentSummarySet']['DocumentSummary'][0]['variation_set'][0]\n",
        "      spdi = varData[\"canonical_spdi\"]\n",
        "    except:\n",
        "      raise RuntimeError(f'Invalid ClinVar ID: {cvID}')\n",
        "    try:\n",
        "       [start, ref, mut] = spdi.split(\":\")[1:]\n",
        "    except:\n",
        "      raise RuntimeError(\"No coordinates available\")\n",
        "    coord = [entry for entry in varData[\"variation_loc\"] if entry['status'] == 'current'][0]\n",
        "    [chrom, assembly_name] = [coord['chr'], coord['assembly_name']]\n",
        "    return {'coords': {'assembly': ASM_MAP[assembly_name],\n",
        "                                  'chrom': \"chr\" + chrom,\n",
        "                                  'pos': start },\n",
        "                        'alleles': { 'vName': varData[\"variation_name\"],\n",
        "                                   'ref': ref,\n",
        "                                   'mut': mut },\n",
        "                        'gene': records['DocumentSummarySet']['DocumentSummary'][0]['gene_sort']}\n",
        "\n",
        "def coordsToRefSeq(coords):\n",
        "    if 'start' in coords and 'end' in coords:\n",
        "        start = coords['start']\n",
        "        end = coords['end']\n",
        "    else:\n",
        "        start = int(coords['pos'])\n",
        "        end = start + 1\n",
        "    query = {'track': 'ccdsGene', 'genome': coords['assembly'], 'chrom': coords['chrom'],\n",
        "                 'start': start, 'end': end}\n",
        "    resp = requests.get(\"https://api.genome.ucsc.edu/getData/track\", params = query)\n",
        "    if not resp.ok: raise RuntimeError(f'Failed to get RefSeq annotations from UCSC: {resp.status_code} {resp.text}')\n",
        "    data = resp.json()\n",
        "    if data['ccdsGene']: return data['ccdsGene'][0]\n",
        "    return None\n",
        "\n",
        "def fetchSequenceFromCoords(coords, contextLen):\n",
        "    [assembly, chrom, pos] = [coords['assembly'], coords['chrom'], int(coords['pos'])]\n",
        "    startPos = pos - contextLen\n",
        "    endPos = pos + contextLen\n",
        "    query = {'genome': assembly, 'chrom': chrom, 'start': startPos, 'end': endPos}\n",
        "    resp = requests.get('https://api.genome.ucsc.edu/getData/sequence', params = query)\n",
        "    if not resp.ok: raise RuntimeError('Failed to fetch sequence from UCSC Genome Browser')\n",
        "    data = resp.json()\n",
        "    return data['dna']\n",
        "\n",
        "def getContextExonTranslations(geneData, target, contextLen):\n",
        "    target = int(target)\n",
        "    contextStart = target - contextLen\n",
        "    contextEnd = target + contextLen\n",
        "    exonStarts = [int(n) for n in geneData[\"exonStarts\"].split(',') if n.isdigit() and int(n) != 0]\n",
        "    exonEnds = [int(n) for n in geneData[\"exonEnds\"].split(',') if n.isdigit() and int(n) != 0]\n",
        "    exonFrames = [int(n) for n in geneData[\"exonFrames\"].split(',') if n.isdigit()]\n",
        "    if geneData['strand'] == '+':\n",
        "        exonStarts[0] = geneData['cdsStart']\n",
        "        exonEnds[-1] = geneData['cdsEnd']\n",
        "        exonFrames[0] = 0\n",
        "    else:\n",
        "        exonStarts[0] = geneData['cdsStart']\n",
        "        exonEnds[-1] = geneData['cdsEnd']\n",
        "        exonFrames[-1] = 0\n",
        "    contentExons = []\n",
        "    for i in range(len(exonStarts)):\n",
        "        if exonStarts[i] <= contextEnd and exonEnds[i] >= contextStart:\n",
        "            exonNumber = i + 1 if geneData['strand'] == '+' else len(exonStarts) - i\n",
        "            startOffset = max(0, exonStarts[i] - contextStart)\n",
        "            endOffset = min(exonEnds[i], contextEnd) - contextStart\n",
        "            adjustedFrame = exonFrames[i]\n",
        "            if exonStarts[i] < contextStart and geneData['strand'] == '+':\n",
        "                distanceFromContextStart = contextStart - exonStarts[i]\n",
        "                adjustedFrame = (exonFrames[i] + distanceFromContextStart) % 3\n",
        "            elif exonEnds[i] > contextEnd and geneData['strand'] == '-':\n",
        "                distanceFromContextStart = exonEnds[i] - contextEnd\n",
        "                adjustedFrame = (exonFrames[i] + distanceFromContextStart) % 3\n",
        "            contentExons.append({'name': f'{geneData[\"name2\"]} Exon {exonNumber}',\n",
        "                                 'start': startOffset, 'end': endOffset, 'direction': geneData['strand'],\n",
        "                                 'frame': (3 - adjustedFrame) % 3})\n",
        "    return contentExons\n",
        "\n",
        "def testReversion(mutCodon, wtAA, verbose = True):\n",
        "    candidates = []\n",
        "    abe_plus = mutCodon.replace('A', 'G')\n",
        "    if Seq.translate(abe_plus) == wtAA:\n",
        "        if verbose: print(f'{mutCodon} could be corrected to {abe_plus}')\n",
        "        candidates.append(['ABE', '+'])\n",
        "    cbe_plus = mutCodon.replace('C', 'T')\n",
        "    if Seq.translate(cbe_plus) == wtAA:\n",
        "        if verbose: print(f'{mutCodon} could be corrected to {cbe_plus}')\n",
        "        candidates.append(['BE4', '+'])\n",
        "    abe_minus = mutCodon.replace('T', 'C')\n",
        "    if Seq.translate(abe_minus) == wtAA:\n",
        "        if verbose: print(f'{mutCodon} could be corrected to {abe_minus}')\n",
        "        candidates.append(['ABE', '-'])\n",
        "    cbe_minus = mutCodon.replace('G', 'A')\n",
        "    if Seq.translate(cbe_minus) == wtAA:\n",
        "        if verbose: print(f'{mutCodon} could be corrected to {cbe_minus}')\n",
        "        candidates.append(['BE4', '-'])\n",
        "    return candidates\n",
        "\n",
        "def isTransition(allele, verbose = True):\n",
        "    if allele['mut'] == 'A' and allele['ref'] == 'G':\n",
        "        if verbose: print('A could be corrected to G')\n",
        "        return ['ABE', '+']\n",
        "    elif allele['mut'] == 'C' and allele['ref'] == 'T':\n",
        "        if verbose: print('C could be corrected to T')\n",
        "        return ['BE4', '+']\n",
        "    elif allele['mut'] == 'T' and allele['ref'] == 'C':\n",
        "        if verbose: print('T could be corrected to C')\n",
        "        return ['ABE', '-']\n",
        "    elif allele['mut'] == 'G' and allele['ref'] == 'A':\n",
        "        if verbose: print('G could be corrected to A')\n",
        "        return ['BE4', '-']\n",
        "    return False\n",
        "\n",
        "def behive(seq50,pred_efficiency=0.5):\n",
        "    with contextlib.redirect_stdout(None):\n",
        "      with contextlib.redirect_stderr(None):\n",
        "        pred_d = be_efficiency_model.predict(seq50)\n",
        "        z = pred_d['Predicted logit score']\n",
        "        pred_real = expit(1.5 * z + logit(pred_efficiency)) * 100\n",
        "        pred_df, stats = bystander_model.predict(seq50)\n",
        "        pred_df = bystander_model.add_genotype_column(pred_df, stats)\n",
        "        percentile = norm.cdf(z) * 100\n",
        "    return {'df':pred_df, 'z':z, 'percentile':percentile, 'target_efficiency':pred_real}\n",
        "\n",
        "def analyze(cvId, email, verbose = True, pred_efficiency = 0.5):\n",
        "    contextLen = 35\n",
        "    results = {}\n",
        "    analysis = {}\n",
        "    stats_dict = []\n",
        "    a = cvIDtoHg38Coords(cvId, email)\n",
        "    vname = a['alleles']['vName']\n",
        "    print(f'ClinVar ID: {cvId}')\n",
        "    print(f'Variant name: {vname}')\n",
        "    if len(a['alleles']['ref']) != 1 or len(a['alleles']['mut']) != 1:\n",
        "        print(f'The mutation with ClinVar ID {cvId} is not a single nucleotide variant.')\n",
        "        return[analysis, stats_dict, vname]\n",
        "    elif a['alleles']['ref'] == a['alleles']['mut']:\n",
        "        print(f'The mutation with ClinVar ID {cvId} has no base change to correct.')\n",
        "        return[analysis, stats_dict, vname]\n",
        "    geneData = coordsToRefSeq(a['coords'])\n",
        "    seq = fetchSequenceFromCoords(a['coords'], contextLen)\n",
        "    seq = seq.upper()\n",
        "    mut = seq[:contextLen] + a['alleles']['mut'] + seq[contextLen+1:]\n",
        "    if geneData: c = getContextExonTranslations(geneData, a['coords']['pos'], contextLen)\n",
        "    else: c = {}\n",
        "    correctExon = None\n",
        "    for exon in c:\n",
        "        seqSlice = seq[exon['start']:exon['end']]\n",
        "        mutSlice = mut[exon['start']:exon['end']]\n",
        "        if exon['direction'] == '-':\n",
        "            seqSlice = Seq.reverse_complement(seqSlice)\n",
        "            mutSlice = Seq.reverse_complement(mutSlice)\n",
        "        seqTranslation = Seq.translate(seqSlice[exon['frame']:len(seqSlice)-((len(seqSlice)-exon['frame'])%3)])\n",
        "        mutTranslation = Seq.translate(mutSlice[exon['frame']:len(seqSlice)-((len(seqSlice)-exon['frame'])%3)])\n",
        "        if verbose:\n",
        "            print('WT:')\n",
        "            print(seqSlice)\n",
        "            print(' ' * exon['frame'] + ''.join([' ' + seqTranslation[aa] + ' ' for aa in range(len(seqTranslation))]))\n",
        "            print(Seq.complement(seqSlice))\n",
        "            print('Variant:')\n",
        "            print(mutSlice)\n",
        "            print(' ' * exon['frame'] + ''.join([' ' + mutTranslation[aa] + ' ' for aa in range(len(mutTranslation))]))\n",
        "            print(Seq.complement(mutSlice))\n",
        "        if contextLen < exon['end'] and contextLen >= exon['start']:\n",
        "            correctExon = exon\n",
        "            if exon['direction'] == '+':\n",
        "                pos = contextLen - exon['start']\n",
        "            elif exon['direction'] == '-':\n",
        "                pos = (exon['end'] - 1) - contextLen\n",
        "            wtCodon = seqSlice[pos - ((pos - exon['frame']) % 3):pos - ((pos - exon['frame']) % 3) + 3]\n",
        "            mutCodon = mutSlice[pos - ((pos - exon['frame']) % 3):pos - ((pos - exon['frame']) % 3) + 3]\n",
        "            if len(wtCodon) == 3 and len(mutCodon) == 3:\n",
        "                wtAA = Seq.translate(wtCodon)\n",
        "                mutAA = Seq.translate(mutCodon)\n",
        "                if verbose: print(f'The wild-type codon {wtCodon}, coding for {wtAA}, is mutated to {mutCodon}, coding for {mutAA}')\n",
        "            else:\n",
        "                correctExon = None\n",
        "    if correctExon:\n",
        "        candidates = testReversion(mutCodon, wtAA, verbose)\n",
        "        if candidates:\n",
        "            for candidate in candidates:\n",
        "                [editor, strand] = candidate\n",
        "                with contextlib.redirect_stdout(None):\n",
        "                    with contextlib.redirect_stderr(None):\n",
        "                        with patch_pickle():\n",
        "                            be_efficiency_model.init_model(base_editor=editor, celltype='mES')\n",
        "                            bystander_model.init_model(base_editor=editor, celltype='mES')\n",
        "                if strand == correctExon['direction']:\n",
        "                    for start in range(17):\n",
        "                        seq50 = mut[start:start+50]\n",
        "                        if verbose: print(f'Sending {seq50} (top strand) to BE-Hive with editor {editor}')\n",
        "                        results[(cvId, start, editor, strand)] = behive(seq50, pred_efficiency)\n",
        "                else:\n",
        "                    mut_rc = Seq.reverse_complement(mut)\n",
        "                    for start in range(17):\n",
        "                        seq50 = mut_rc[start:start+50]\n",
        "                        if verbose: print(f'Sending {seq50} (bottom strand) to BE-Hive with editor {editor}')\n",
        "                        results[(cvId, start, editor, strand)] = behive(seq50, pred_efficiency)\n",
        "            seqSlice = seq[correctExon['start']:correctExon['end']]\n",
        "            if correctExon['direction'] == '-':\n",
        "                seqSlice = Seq.reverse_complement(seqSlice)\n",
        "            seqTranslation = Seq.translate(seqSlice[correctExon['frame']:len(seqSlice)-((len(seqSlice)-correctExon['frame'])%3)])\n",
        "            for entry in results:\n",
        "                (cvId, start, editor, strand) = entry\n",
        "                df = results[entry]['df']\n",
        "                z = results[entry]['z']\n",
        "                percentile = results[entry]['percentile']\n",
        "                target_efficiency = results[entry]['target_efficiency']\n",
        "                perfect_correction = 0\n",
        "                if strand == correctExon['direction']:\n",
        "                    spacer = mut[start+20:start+40]\n",
        "                    pam = mut[start+40:start+44]\n",
        "                else:\n",
        "                    mut_rc = Seq.reverse_complement(mut)\n",
        "                    spacer = mut_rc[start+20:start+40]\n",
        "                    pam = mut_rc[start+40:start+44]\n",
        "                params = (editor, spacer, pam)\n",
        "                analysis[params] = {}\n",
        "                for p, genotype in zip(df['Predicted frequency'], df['Genotype']):\n",
        "                    if strand == correctExon['direction']:\n",
        "                        mut_edited = mut[:start] + genotype + mut[start+50:]\n",
        "                    else:\n",
        "                        mut_rc_edited = mut_rc[:start] + genotype + mut_rc[start+50:]\n",
        "                        mut_edited = Seq.reverse_complement(mut_rc_edited)\n",
        "                    mutSlice = mut_edited[correctExon['start']:correctExon['end']]\n",
        "                    if correctExon['direction'] == '-': mutSlice = Seq.reverse_complement(mutSlice)\n",
        "                    mutTranslation = Seq.translate(mutSlice[correctExon['frame']:len(seqSlice)-((len(seqSlice)-correctExon['frame'])%3)])\n",
        "                    if seqTranslation == mutTranslation:\n",
        "                        perfect_correction += p\n",
        "                    if mutTranslation not in analysis[params]: analysis[params][mutTranslation] = 0\n",
        "                    analysis[params][mutTranslation] += p\n",
        "                stats_dict.append({'ClinVar ID': cvId, 'Variant name': vname, 'Editor': editor, 'Spacer': spacer, 'PAM': pam, 'Perfect correction': perfect_correction,\n",
        "                                     'Z-score': z, 'Percentile': percentile, 'Target efficiency': target_efficiency})\n",
        "        else: print(f'The coding mutation with ClinVar ID {cvId} is unlikely to be correctable via canonical base editing. Try prime editing instead.')\n",
        "    else:\n",
        "        transition = isTransition(a['alleles'])\n",
        "        if transition:\n",
        "            [editor, strand] = transition\n",
        "            with contextlib.redirect_stdout(None):\n",
        "                with contextlib.redirect_stderr(None):\n",
        "                    with patch_pickle():\n",
        "                        be_efficiency_model.init_model(base_editor=editor, celltype='mES')\n",
        "                        bystander_model.init_model(base_editor=editor, celltype='mES')\n",
        "            if strand == '+':\n",
        "                for start in range(17):\n",
        "                    seq50 = mut[start:start+50]\n",
        "                    if verbose: print(f'Sending {seq50} (top strand) to BE-Hive with editor {editor}')\n",
        "                    results[(cvId, start, editor, strand)] = behive(seq50, pred_efficiency)\n",
        "            elif strand == '-':\n",
        "                for start in range(17):\n",
        "                    seq50 = Seq.reverse_complement(mut)[start:start+50]\n",
        "                    if verbose: print(f'Sending {seq50} (bottom strand) to BE-Hive with editor {editor}')\n",
        "                    results[(cvId, start, editor, strand)] = behive(seq50, pred_efficiency)\n",
        "            for entry in results:\n",
        "                (cvId, start, editor, strand) = entry\n",
        "                df = results[entry]['df']\n",
        "                z = results[entry]['z']\n",
        "                percentile = results[entry]['percentile']\n",
        "                target_efficiency = results[entry]['target_efficiency']\n",
        "                perfect_correction = 0\n",
        "                if strand == '+':\n",
        "                    spacer = mut[start+20:start+40]\n",
        "                    pam = mut[start+40:start+44]\n",
        "                elif strand == '-':\n",
        "                    mut_rc = Seq.reverse_complement(mut)\n",
        "                    spacer = mut_rc[start+20:start+40]\n",
        "                    pam = mut_rc[start+40:start+44]\n",
        "                params = (editor, spacer, pam)\n",
        "                analysis[params] = {}\n",
        "                for p, genotype in zip(df['Predicted frequency'], df['Genotype']):\n",
        "                    if strand == '+':\n",
        "                        mut_edited = mut[:start] + genotype + mut[start+50:]\n",
        "                    elif strand == '-':\n",
        "                        mut_rc_edited = mut_rc[:start] + genotype + mut_rc[start+50:]\n",
        "                        mut_edited = Seq.reverse_complement(mut_rc_edited)\n",
        "                    if seq == mut_edited:\n",
        "                        perfect_correction += p\n",
        "                    if mut_edited not in analysis[params]: analysis[params][mut_edited] = 0\n",
        "                    analysis[params][mut_edited] += p\n",
        "                stats_dict.append({'ClinVar ID': cvId, 'Variant name': vname, 'Editor': editor, 'Spacer': spacer, 'PAM': pam, 'Perfect correction': perfect_correction,\n",
        "                                   'Z-score': z, 'Percentile': percentile, 'Target efficiency': target_efficiency})\n",
        "        else: print(f'The non-coding mutation with ClinVar ID {cvId} is not accesible to canonical base editing. Try prime editing instead.')\n",
        "    print('Done')\n",
        "    return [analysis, stats_dict, vname]\n",
        "\n",
        "def append(\n",
        "    self,\n",
        "    other,\n",
        "    ignore_index: bool = False,\n",
        "    verify_integrity: bool = False,\n",
        "    sort: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Append rows of `other` to the end of caller, returning a new object.\n",
        "\n",
        "    .. deprecated:: 1.4.0\n",
        "        Use :func:`concat` instead. For further details see\n",
        "        :ref:`whatsnew_140.deprecations.frame_series_append`\n",
        "\n",
        "    Columns in `other` that are not in the caller are added as new columns.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    other : DataFrame or Series/dict-like object, or list of these\n",
        "        The data to append.\n",
        "    ignore_index : bool, default False\n",
        "        If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
        "    verify_integrity : bool, default False\n",
        "        If True, raise ValueError on creating index with duplicates.\n",
        "    sort : bool, default False\n",
        "        Sort columns if the columns of `self` and `other` are not aligned.\n",
        "\n",
        "        .. versionchanged:: 1.0.0\n",
        "\n",
        "            Changed to not sort by default.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame\n",
        "        A new DataFrame consisting of the rows of caller and the rows of `other`.\n",
        "\n",
        "    See Also\n",
        "    --------\n",
        "    concat : General function to concatenate DataFrame or Series objects.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    If a list of dict/series is passed and the keys are all contained in\n",
        "    the DataFrame's index, the order of the columns in the resulting\n",
        "    DataFrame will be unchanged.\n",
        "\n",
        "    Iteratively appending rows to a DataFrame can be more computationally\n",
        "    intensive than a single concatenate. A better solution is to append\n",
        "    those rows to a list and then concatenate the list with the original\n",
        "    DataFrame all at once.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y'])\n",
        "    >>> df\n",
        "        A  B\n",
        "    x  1  2\n",
        "    y  3  4\n",
        "    >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y'])\n",
        "    >>> df.append(df2)\n",
        "        A  B\n",
        "    x  1  2\n",
        "    y  3  4\n",
        "    x  5  6\n",
        "    y  7  8\n",
        "\n",
        "    With `ignore_index` set to True:\n",
        "\n",
        "    >>> df.append(df2, ignore_index=True)\n",
        "        A  B\n",
        "    0  1  2\n",
        "    1  3  4\n",
        "    2  5  6\n",
        "    3  7  8\n",
        "\n",
        "    The following, while not recommended methods for generating DataFrames,\n",
        "    show two ways to generate a DataFrame from multiple data sources.\n",
        "\n",
        "    Less efficient:\n",
        "\n",
        "    >>> df = pd.DataFrame(columns=['A'])\n",
        "    >>> for i in range(5):\n",
        "    ...     df = df.append({'A': i}, ignore_index=True)\n",
        "    >>> df\n",
        "        A\n",
        "    0  0\n",
        "    1  1\n",
        "    2  2\n",
        "    3  3\n",
        "    4  4\n",
        "\n",
        "    More efficient:\n",
        "\n",
        "    >>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
        "    ...           ignore_index=True)\n",
        "        A\n",
        "    0  0\n",
        "    1  1\n",
        "    2  2\n",
        "    3  3\n",
        "    4  4\n",
        "    \"\"\"\n",
        "\n",
        "    return self._append(other, ignore_index, verify_integrity, sort)\n",
        "\n",
        "def _append(\n",
        "    self,\n",
        "    other,\n",
        "    ignore_index: bool = False,\n",
        "    verify_integrity: bool = False,\n",
        "    sort: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    combined_columns = None\n",
        "    if isinstance(other, (pd.Series, dict)):\n",
        "        if isinstance(other, dict):\n",
        "            if not ignore_index:\n",
        "                raise TypeError(\"Can only append a dict if ignore_index=True\")\n",
        "            other = pd.Series(other)\n",
        "        if other.name is None and not ignore_index:\n",
        "            raise TypeError(\n",
        "                \"Can only append a Series if ignore_index=True \"\n",
        "                \"or if the Series has a name\"\n",
        "            )\n",
        "\n",
        "        index = pd.Index([other.name], name=self.index.name)\n",
        "        idx_diff = other.index.difference(self.columns)\n",
        "        combined_columns = self.columns.append(idx_diff)\n",
        "        row_df = other.to_frame().T\n",
        "        # infer_objects is needed for\n",
        "        #  test_append_empty_frame_to_series_with_dateutil_tz\n",
        "        other = row_df.infer_objects().rename_axis(index.names, copy=False)\n",
        "    elif isinstance(other, list):\n",
        "        if not other:\n",
        "            pass\n",
        "        elif not isinstance(other[0], pd.DataFrame):\n",
        "            other = pd.DataFrame(other)\n",
        "            if self.index.name is not None and not ignore_index:\n",
        "                other.index.name = self.index.name\n",
        "\n",
        "    from pandas.core.reshape.concat import concat\n",
        "\n",
        "    if isinstance(other, (list, tuple)):\n",
        "        to_concat = [self, *other]\n",
        "    else:\n",
        "        to_concat = [self, other]\n",
        "\n",
        "    result = concat(\n",
        "        to_concat,\n",
        "        ignore_index=ignore_index,\n",
        "        verify_integrity=verify_integrity,\n",
        "        sort=sort,\n",
        "    )\n",
        "    if (\n",
        "        combined_columns is not None\n",
        "        and not sort\n",
        "        and not combined_columns.equals(result.columns)\n",
        "    ):\n",
        "        # TODO: reindexing here is a kludge bc union_indexes does not\n",
        "        #  pass sort to index.union, xref #43375\n",
        "        # combined_columns.equals check is necessary for preserving dtype\n",
        "        #  in test_crosstab_normalize\n",
        "        result = result.reindex(combined_columns, axis=1)\n",
        "    return result.__finalize__(self, method=\"append\")\n",
        "pd.DataFrame.append = append\n",
        "pd.DataFrame._append = _append"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title (Optional) Search ClinVar for ClinVar IDs { display-mode: \"form\" }\n",
        "# @markdown This section can be used to find ClinVar IDs for mutations of interest. It can be run as many times as needed before starting analysis by clicking the \"Play\" button to the left. Before running for the first time, also execute the \"Mount Google Drive and install/import libraries\" section above.\n",
        "email = 'liangus@broadinstitute.org' # @param {type:\"string\"}\n",
        "# @markdown - An email address is required for Entrez searches for ClinVar records. We do not store your email.\n",
        "search_term = \"KIF1A T99M\" # @param {type:\"string\"}\n",
        "max_record_number = 100 # @param {type:\"integer\"}\n",
        "if search_term:\n",
        "  Entrez.email = email\n",
        "  handle = Entrez.esearch(db='clinvar', retmax = max(1, max_record_number), term=search_term)\n",
        "  record = Entrez.read(handle)\n",
        "  cvIds_search = record['IdList']\n",
        "  post = Entrez.read(Entrez.epost('clinvar', id=','.join(cvIds_search)))\n",
        "  webenv = post['WebEnv']\n",
        "  query_key = post['QueryKey']\n",
        "  records = Entrez.read(Entrez.esummary(db='clinvar', query_key=query_key, WebEnv=webenv), validate = False)\n",
        "  df = pd.DataFrame.from_dict(records['DocumentSummarySet']['DocumentSummary'])\n",
        "  df = df[['title','gene_sort','chr_sort','location_sort','obj_type','protein_change','germline_classification']]\n",
        "  df.insert(0, 'ClinVar ID', cvIds_search)\n",
        "  df['germline_classification'] = df['germline_classification'].apply(lambda x: x['description'])\n",
        "  display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "_MorcrwER0z2",
        "outputId": "0c1b69b2-d05f-4002-9704-9ec4e6a6f6f8"
      },
      "id": "_MorcrwER0z2",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ClinVar ID                                         title gene_sort chr_sort  \\\n",
              "0     432272  NM_001244008.2(KIF1A):c.308A>C (p.Lys103Thr)     KIF1A       02   \n",
              "1      30169   NM_001244008.2(KIF1A):c.296C>T (p.Thr99Met)     KIF1A       02   \n",
              "\n",
              "          location_sort                   obj_type protein_change  \\\n",
              "0  00000000000240788106  single nucleotide variant          K103T   \n",
              "1  00000000000240788118  single nucleotide variant           T99M   \n",
              "\n",
              "  germline_classification  \n",
              "0              Pathogenic  \n",
              "1              Pathogenic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e55ca7c-4a12-4e20-b499-04f3ac852990\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ClinVar ID</th>\n",
              "      <th>title</th>\n",
              "      <th>gene_sort</th>\n",
              "      <th>chr_sort</th>\n",
              "      <th>location_sort</th>\n",
              "      <th>obj_type</th>\n",
              "      <th>protein_change</th>\n",
              "      <th>germline_classification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>432272</td>\n",
              "      <td>NM_001244008.2(KIF1A):c.308A&gt;C (p.Lys103Thr)</td>\n",
              "      <td>KIF1A</td>\n",
              "      <td>02</td>\n",
              "      <td>00000000000240788106</td>\n",
              "      <td>single nucleotide variant</td>\n",
              "      <td>K103T</td>\n",
              "      <td>Pathogenic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30169</td>\n",
              "      <td>NM_001244008.2(KIF1A):c.296C&gt;T (p.Thr99Met)</td>\n",
              "      <td>KIF1A</td>\n",
              "      <td>02</td>\n",
              "      <td>00000000000240788118</td>\n",
              "      <td>single nucleotide variant</td>\n",
              "      <td>T99M</td>\n",
              "      <td>Pathogenic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e55ca7c-4a12-4e20-b499-04f3ac852990')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e55ca7c-4a12-4e20-b499-04f3ac852990 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e55ca7c-4a12-4e20-b499-04f3ac852990');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d63af05e-19c7-4d41-94e5-33b19c5b67c3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d63af05e-19c7-4d41-94e5-33b19c5b67c3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d63af05e-19c7-4d41-94e5-33b19c5b67c3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8ea38285-65af-4aee-8988-ccd4ce2f2ec6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8ea38285-65af-4aee-8988-ccd4ce2f2ec6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"ClinVar ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"30169\",\n          \"432272\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NM_001244008.2(KIF1A):c.296C>T (p.Thr99Met)\",\n          \"NM_001244008.2(KIF1A):c.308A>C (p.Lys103Thr)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gene_sort\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"KIF1A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chr_sort\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location_sort\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"00000000000240788118\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"obj_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"single nucleotide variant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_change\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"T99M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"germline_classification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Pathogenic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            },
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/9e65f7085e7ffcb7/data_table.js\";\n\n      const table = window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"432272\",\n\"NM_001244008.2(KIF1A):c.308A>C (p.Lys103Thr)\",\n\"KIF1A\",\n\"02\",\n\"00000000000240788106\",\n\"single nucleotide variant\",\n\"K103T\",\n\"Pathogenic\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"30169\",\n\"NM_001244008.2(KIF1A):c.296C>T (p.Thr99Met)\",\n\"KIF1A\",\n\"02\",\n\"00000000000240788118\",\n\"single nucleotide variant\",\n\"T99M\",\n\"Pathogenic\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"ClinVar ID\"], [\"string\", \"title\"], [\"string\", \"gene_sort\"], [\"string\", \"chr_sort\"], [\"string\", \"location_sort\"], [\"string\", \"obj_type\"], [\"string\", \"protein_change\"], [\"string\", \"germline_classification\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n\n      function appendQuickchartButton(parentElement) {\n        let quickchartButtonContainerElement = document.createElement('div');\n        quickchartButtonContainerElement.innerHTML = `\n    <div id=\"df-af627c0e-82cd-485a-852f-c058c763d154\">\n      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af627c0e-82cd-485a-852f-c058c763d154')\"\n                title=\"Suggest charts\"\n                style=\"display:none;\">\n\n<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n     width=\"24px\">\n    <g>\n        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n    </g>\n</svg>\n      </button>\n\n<style>\n  .colab-df-quickchart {\n      --bg-color: #E8F0FE;\n      --fill-color: #1967D2;\n      --hover-bg-color: #E2EBFA;\n      --hover-fill-color: #174EA6;\n      --disabled-fill-color: #AAA;\n      --disabled-bg-color: #DDD;\n  }\n\n  [theme=dark] .colab-df-quickchart {\n      --bg-color: #3B4455;\n      --fill-color: #D2E3FC;\n      --hover-bg-color: #434B5C;\n      --hover-fill-color: #FFFFFF;\n      --disabled-bg-color: #3B4455;\n      --disabled-fill-color: #666;\n  }\n\n  .colab-df-quickchart {\n    background-color: var(--bg-color);\n    border: none;\n    border-radius: 50%;\n    cursor: pointer;\n    display: none;\n    fill: var(--fill-color);\n    height: 32px;\n    padding: 0;\n    width: 32px;\n  }\n\n  .colab-df-quickchart:hover {\n    background-color: var(--hover-bg-color);\n    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n    fill: var(--button-hover-fill-color);\n  }\n\n  .colab-df-quickchart-complete:disabled,\n  .colab-df-quickchart-complete:disabled:hover {\n    background-color: var(--disabled-bg-color);\n    fill: var(--disabled-fill-color);\n    box-shadow: none;\n  }\n\n  .colab-df-spinner {\n    border: 2px solid var(--fill-color);\n    border-color: transparent;\n    border-bottom-color: var(--fill-color);\n    animation:\n      spin 1s steps(1) infinite;\n  }\n\n  @keyframes spin {\n    0% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n      border-left-color: var(--fill-color);\n    }\n    20% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    30% {\n      border-color: transparent;\n      border-left-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n      border-right-color: var(--fill-color);\n    }\n    40% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-top-color: var(--fill-color);\n    }\n    60% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n    }\n    80% {\n      border-color: transparent;\n      border-right-color: var(--fill-color);\n      border-bottom-color: var(--fill-color);\n    }\n    90% {\n      border-color: transparent;\n      border-bottom-color: var(--fill-color);\n    }\n  }\n</style>\n\n      <script>\n        async function quickchart(key) {\n          const quickchartButtonEl =\n            document.querySelector('#' + key + ' button');\n          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n          quickchartButtonEl.classList.add('colab-df-spinner');\n          try {\n            const charts = await google.colab.kernel.invokeFunction(\n                'suggestCharts', [key], {});\n          } catch (error) {\n            console.error('Error during call to suggestCharts:', error);\n          }\n          quickchartButtonEl.classList.remove('colab-df-spinner');\n          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n        }\n        (() => {\n          let quickchartButtonEl =\n            document.querySelector('#df-af627c0e-82cd-485a-852f-c058c763d154 button');\n          quickchartButtonEl.style.display =\n            google.colab.kernel.accessAllowed ? 'block' : 'none';\n        })();\n      </script>\n    </div>`;\n        parentElement.appendChild(quickchartButtonContainerElement);\n      }\n\n      appendQuickchartButton(table);\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Perform analysis and download results { display-mode: \"form\" }\n",
        "# @markdown When all parameters have been specified, start analysis by clicking the \"Play\" button to the left. A CPU runtime is sufficient.\n",
        "project_name = 'KIF1A T99M' # @param {type:\"string\"}\n",
        "# @markdown - A project name is optional but can help distinguish between multiple analyses.\n",
        "email = 'liangus@broadinstitute.org' # @param {type:\"string\"}\n",
        "# @markdown - An email address is required for Entrez searches for ClinVar records. We do not store your email.\n",
        "mode = 'Enter ClinVar IDs directly' # @param [\"Upload a spreadsheet containing ClinVar IDs\", \"Enter a gene name\", \"Enter ClinVar IDs directly\", \"Use all ClinVar search results from above\"]\n",
        "# @markdown - Inputs for modes other than the one selected will be ignored. Excel and CSV files are supported for upload. If applicable, you will be prompted to upload after clicking the \"Play\" button to the left.\n",
        "spreadsheet_has_headers = True # @param {type:\"boolean\"}\n",
        "# @markdown - If you are uploading a spreadsheet with column headers, select `spreadsheet_has_headers` and enter the name of the column with ClinVar IDs here.\n",
        "spreadsheet_column = 'VariationID' # @param {type:\"string\"}\n",
        "# @markdown - If you are uploading a spreadsheet with column headers, specify the name of the column containing ClinVar IDs here. If your spreadsheet does not contain headers, the first column of the spreadsheet will automatically be used to retrieve the list of ClinVar IDs.\n",
        "gene = 'KIF1A' # @param {type:\"string\"}\n",
        "# @markdown - To search for corrective base editing strategies to all pathogenic/likely pathogenic mutations in a gene documented in ClinVar (may take a long time), use the \"Enter a gene name\" mode.\n",
        "clinVar_ids = '30169' # @param {type:\"string\"}\n",
        "# @markdown - ClinVar IDs found using the search form above can be entered here. ClinVar IDs can be separated by any mix of spaces, commas, and/or semicolons. This list will be used if the \"Enter ClinVar IDs directly\" mode is selected.\n",
        "average_editing_efficiency = 0.5 # @param {type:\"slider\", min:0.01, max:0.99, step:0.01}\n",
        "# @markdown - Specify the average editing efficiency of your base editor in `average_editing_efficiency`. This only affects the predicted editing efficiency at each target and will not alter the list of suggested editing strategies.\n",
        "threshold = 0.6 # @param {type:\"slider\", min:0.01, max:0.99, step:0.01}\n",
        "# @markdown - Use `threshold` to specify the cutoff threshold for predicted edit purity required for inclusion in the abbreviated summary of high-potential editor candidates. For coding mutations, purity is measured by exact match to reference translated protein sequence. For non-coding mutations, purity is measured by exact DNA sequence match to reference. This does not alter the full editor analysis that is also provided.\n",
        "verbose_output = True # @param {type:\"boolean\"}\n",
        "# @markdown - Selecting `verbose_output` will provide a running summary of edit strategies being tested. If deselected, only the current ClinVar ID and variant name being tested will be displayed.\n",
        "\n",
        "if mode == \"Enter ClinVar IDs directly\":\n",
        "  cvIds = re.split(r'[ ,;\\t]+', clinVar_ids)\n",
        "elif mode == \"Enter a gene name\":\n",
        "  Entrez.email = email\n",
        "  handle = Entrez.esearch(db='clinvar', retmax = 5000, term=f'(((\"{gene}\"[Gene Name]) AND \"single nucleotide variant\"[Type of variation]) AND (\"clinsig pathogenic\"[Filter] OR \"clinsig likely path\"[Filter]))')\n",
        "  record = Entrez.read(handle)\n",
        "  cvIds = record['IdList']\n",
        "elif mode == \"Upload a spreadsheet containing ClinVar IDs\":\n",
        "  uploaded = {}\n",
        "  while len(uploaded.keys()) != 1:\n",
        "    print('Please upload a single spreadsheet containing ClinVar IDs to be analyzed.')\n",
        "    uploaded = files.upload()\n",
        "  fname = list(uploaded.keys())[0]\n",
        "  ext = fname.split('.')[-1]\n",
        "  if ext == 'xlsx' or ext == 'xls':\n",
        "    if not spreadsheet_has_headers:\n",
        "      df = pd.read_excel(io.BytesIO(uploaded[fname]), header = None)\n",
        "      cvIds = df.iloc[:, 0].to_list()\n",
        "    else:\n",
        "      df = pd.read_excel(io.BytesIO(uploaded[fname]))\n",
        "      cvIds = df[spreadsheet_column].to_list()\n",
        "  elif ext == 'csv':\n",
        "    if not spreadsheet_has_headers:\n",
        "      df = pd.read_csv(io.BytesIO(uploaded[fname]), header = None)\n",
        "      cvIds = df.iloc[:, 0].to_list()\n",
        "    else:\n",
        "      df = pd.read_csv(io.BytesIO(uploaded[fname]))\n",
        "      cvIds = df[spreadsheet_column].to_list()\n",
        "  else: raise Exception('Unsupported file type')\n",
        "  cvIds = [str(int(cvId)) for cvId in cvIds if not np.isnan(cvId)]\n",
        "elif mode == \"Use all ClinVar search results from above\":\n",
        "  try: cvIds = cvIds_search\n",
        "  except: print('No ClinVar search was run in the current session. Run a ClinVar search and try again.')\n",
        "\n",
        "\n",
        "homedir = '/content/gdrive/MyDrive'\n",
        "timestamp = datetime.now().strftime('%Y-%m-%d %HH %MM %SS')\n",
        "os.mkdir(os.path.join(homedir,f'ColabBE {project_name} {timestamp}'))\n",
        "run = 1\n",
        "candidates = []\n",
        "hits = {}\n",
        "for cvId in cvIds:\n",
        "    print(f'Run {run} of {len(cvIds)}')\n",
        "    try:\n",
        "      [sequence_distributions, stats_dict, vname] = analyze(cvId, email, verbose_output, average_editing_efficiency)\n",
        "      if stats_dict:\n",
        "          with pd.ExcelWriter(os.path.join(homedir,f'ColabBE {project_name} {timestamp}',f'{cvId} ({vname.replace(\":\",\" \")}) predicted sequence distributions.xlsx')) as seq_dist:\n",
        "              for entry in sequence_distributions:\n",
        "                  (editor, spacer, pam) = entry\n",
        "                  df_seq = pd.DataFrame.from_dict(sequence_distributions[entry], orient='index', columns=['Frequency'])\n",
        "                  df_seq.to_excel(seq_dist, sheet_name=f'{editor} {spacer}|{pam}', index_label='Sequence')\n",
        "          for entry in stats_dict:\n",
        "              if entry['PAM'] in pam_dict:\n",
        "                entry['HT-PAMDA score'] = pam_dict[entry['PAM']]['max_score']\n",
        "                if pam_dict[entry['PAM']]['max_score'] < -3:\n",
        "                  entry['Recommended Cas9 variant'] = f\"Non-SpCas9 (Best SpCas9: {pam_dict[entry['PAM']]['best_PAM']})\"\n",
        "                else:\n",
        "                  entry['Recommended Cas9 variant'] = pam_dict[entry['PAM']]['best_PAM']\n",
        "              else:\n",
        "                entry['HT-PAMDA score'] = 'N/A'\n",
        "                entry['Recommended Cas9 variant'] = 'Non-SpCas9'\n",
        "              if entry['Perfect correction'] >= threshold:\n",
        "                  candidates.append(entry)\n",
        "                  hits[entry['ClinVar ID']] = entry['Variant name']\n",
        "          df_stats = pd.DataFrame.from_dict(stats_dict)\n",
        "          df_stats.to_excel(os.path.join(homedir,f'ColabBE {project_name} {timestamp}',f'{cvId} ({vname.replace(\":\",\" \")}) predicted base editing statistics.xlsx'))\n",
        "    except RuntimeError as inst:\n",
        "        print(inst)\n",
        "    run += 1\n",
        "df_summary = pd.DataFrame.from_dict(candidates)\n",
        "df_summary.to_excel(os.path.join(homedir,f'ColabBE {project_name} {timestamp}',f'{project_name} summary of editor candidates above threshold.xlsx'))\n",
        "df_hits = pd.DataFrame.from_dict(hits, orient='index', columns=['Variant name'])\n",
        "df_hits.to_excel(os.path.join(homedir,f'ColabBE {project_name} {timestamp}',f'{project_name} variants with editor candidates above threshold.xlsx'), index_label='ClinVar ID')\n",
        "shutil.make_archive(os.path.join(homedir, f'ColabBE {project_name} {timestamp}'), \"zip\", os.path.join(homedir, f'ColabBE {project_name} {timestamp}'))\n",
        "files.download(os.path.join(homedir, f'ColabBE {project_name} {timestamp}.zip'))"
      ],
      "metadata": {
        "id": "tkO5jMy1Tfg5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "3c66e0a9-78fb-4080-d100-08c869d42dce"
      },
      "id": "tkO5jMy1Tfg5",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 1\n",
            "ClinVar ID: 30169\n",
            "Variant name: NM_001244008.2(KIF1A):c.296C>T (p.Thr99Met)\n",
            "WT:\n",
            "GGATACAACGTGTGCATCTTCGCCTATGGGCAGACGGGTGCCGGCAAGTCCTACACCATGATGGGCAAGC\n",
            " G  Y  N  V  C  I  F  A  Y  G  Q  T  G  A  G  K  S  Y  T  M  M  G  K \n",
            "CCTATGTTGCACACGTAGAAGCGGATACCCGTCTGCCCACGGCCGTTCAGGATGTGGTACTACCCGTTCG\n",
            "Variant:\n",
            "GGATACAACGTGTGCATCTTCGCCTATGGGCAGATGGGTGCCGGCAAGTCCTACACCATGATGGGCAAGC\n",
            " G  Y  N  V  C  I  F  A  Y  G  Q  M  G  A  G  K  S  Y  T  M  M  G  K \n",
            "CCTATGTTGCACACGTAGAAGCGGATACCCGTCTACCCACGGCCGTTCAGGATGTGGTACTACCCGTTCG\n",
            "The wild-type codon ACG, coding for T, is mutated to ATG, coding for M\n",
            "ATG could be corrected to ACG\n",
            "Sending GCTTGCCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCG (top strand) to BE-Hive with editor ABE\n",
            "Sending CTTGCCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGA (top strand) to BE-Hive with editor ABE\n",
            "Sending TTGCCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAA (top strand) to BE-Hive with editor ABE\n",
            "Sending TGCCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAG (top strand) to BE-Hive with editor ABE\n",
            "Sending GCCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGA (top strand) to BE-Hive with editor ABE\n",
            "Sending CCCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGAT (top strand) to BE-Hive with editor ABE\n",
            "Sending CCATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATG (top strand) to BE-Hive with editor ABE\n",
            "Sending CATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGC (top strand) to BE-Hive with editor ABE\n",
            "Sending ATCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCA (top strand) to BE-Hive with editor ABE\n",
            "Sending TCATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCAC (top strand) to BE-Hive with editor ABE\n",
            "Sending CATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACA (top strand) to BE-Hive with editor ABE\n",
            "Sending ATGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACAC (top strand) to BE-Hive with editor ABE\n",
            "Sending TGGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACACG (top strand) to BE-Hive with editor ABE\n",
            "Sending GGTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACACGT (top strand) to BE-Hive with editor ABE\n",
            "Sending GTGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACACGTT (top strand) to BE-Hive with editor ABE\n",
            "Sending TGTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACACGTTG (top strand) to BE-Hive with editor ABE\n",
            "Sending GTAGGACTTGCCGGCACCCATCTGCCCATAGGCGAAGATGCACACGTTGT (top strand) to BE-Hive with editor ABE\n",
            "Done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54d69f23-eaff-4f20-b23d-4e503b47e59e\", \"ColabBE KIF1A T99M 2025-09-10 21H 09M 39S.zip\", 52197)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mlfold",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}